{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ad646a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass Initial Test, Moving on to Loading Session...\n",
      "\n",
      "Processing: x=0, y=recording1, exp=experiment1, yy=recording1\n",
      "\n",
      "EXPERIMENT1, Recording 1\n",
      "Open Ephys GUI Recording\n",
      "ID: 0x178c0143dd0\n",
      "Format: Binary\n",
      "Directory: HRPilot-05_FirstChronicTest1_2025-08-27_17-17-00_001\\Record Node 106\\experiment1\\recording1\n",
      "Experiment Index: 0\n",
      "Recording Index: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ContinuousMetadata' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m#recording.compute_global_timestamps()\u001b[39;00m\n\u001b[32m    103\u001b[39m metadata = recording.continuous[\u001b[32m0\u001b[39m].metadata\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m channel_names = \u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mchannel_names\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mChannels:\u001b[39m\u001b[33m\"\u001b[39m, channel_names, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    107\u001b[39m timestamps = recording.continuous[\u001b[32m0\u001b[39m].timestamps\n",
      "\u001b[31mTypeError\u001b[39m: 'ContinuousMetadata' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from open_ephys.analysis import Session\n",
    "import os\n",
    "import re\n",
    "from scipy.signal import butter, filtfilt, lfilter\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# ==== Select Session ====\n",
    "w = 0  # recordnode index 1 = Record Node 111 RAW is Offline Filtered\n",
    "u = 0       # recordnode index 0 = Record Node 106 is Online Filtered\n",
    "\n",
    "\n",
    "m_wave_start, m_wave_end = 2, 5\n",
    "h_wave_start, h_wave_end = 5.5, 10\n",
    "\n",
    "\n",
    "def scan_experiment_structure(session_dir, record_node_name=\"Record Node 106\"):\n",
    "    node_path = os.path.join(session_dir, record_node_name)\n",
    "    \n",
    "    if not os.path.exists(node_path):\n",
    "        print(f\"Record Node directory not found: {node_path}\")\n",
    "        return {}\n",
    "    \n",
    "    experiment_info = defaultdict(list)\n",
    "    for item in sorted(os.listdir(node_path)):\n",
    "        exp_path = os.path.join(node_path, item)\n",
    "        if os.path.isdir(exp_path) and item.startswith(\"experiment\"):\n",
    "            recordings = [r for r in sorted(os.listdir(exp_path)) \n",
    "                          if os.path.isdir(os.path.join(exp_path, r)) and r.startswith(\"recording\")]\n",
    "            experiment_info[item] = recordings\n",
    "    return experiment_info\n",
    "\n",
    "# ==== Load Session ====\n",
    "#directory = 'SAP-55_2025-06-09_11-12-19_001'\n",
    "#directory = 'SNARE-31_2025-07-22_17-09-49_002'\n",
    "\n",
    "#directory = 'SNARE-38_2025-07-24_13-43-28_002'\n",
    "\n",
    "#directory = 'SNARE-38-TEST2_2025-07-24_15-59-14_001'\n",
    "#directory = 'SNARE-38-TEST3_2025-07-24_16-05-17_002'\n",
    "#directory = 'SEQ-05_TEST12025-08-06_15-38-15_001'\n",
    "\n",
    "\n",
    "\n",
    "#directory = 'SEQ-06/SEQ-6_TEST2025-08-13_13-12-10_001'\n",
    "#directory = 'SEQ-06/SEQ-6_TRAIN2025-08-13_15-57-16_002'\n",
    "\n",
    "#directory = 'SEQ-06/SEQ-6_TRAIN2_2025-08-13_16-52-15_003'\n",
    "\n",
    "#directory = 'REG-03/REG-03-RAMP2_2025-08-19_17-53-12_002'\n",
    "#directory = 'REG-03/REG-03-TRAIN_2025-08-19_19-07-25_003'\n",
    "\n",
    "directory = 'HRPilot-05_FirstChronicTest1_2025-08-27_17-17-00_001'\n",
    "#directory = 'HRPilot-05_FirstChronicTest1_2025-08-27_17-17-00_001'\n",
    "\n",
    "#directory = 'MDL-155_Electrode_Placement1_2025-11-18_13-43-38_001'\n",
    "\n",
    "session = Session(directory)\n",
    "print('Pass Initial Test, Moving on to Loading Session...\\n')\n",
    "\n",
    "# === Scan structure ===\n",
    "record_node_name = \"Record Node 106\" if w == 0 else \"Record Node 111\"\n",
    "structure = scan_experiment_structure(directory, record_node_name)\n",
    "#record_node_name_offline = \"Record Node 111\" if u == 0 else \"Record Node 106\"\n",
    "#structure_offline = scan_experiment_structure(directory, record_node_name_offline)\n",
    "\n",
    "# === Flatten experiment-recording pairs to loop ===\n",
    "flat_recordings = []\n",
    "for exp_name, rec_list in structure.items():\n",
    "    for rec in rec_list:\n",
    "        flat_recordings.append((exp_name, rec))\n",
    "\n",
    "# === Iterate over recordings with x, y, yy convention ===\n",
    "for x, (exp, yy) in enumerate(flat_recordings):\n",
    "    y = f\"recording{x + 1}\"  # sequential label used in some parts of your code\n",
    "    v = f\"Record Node 106\" if w == 0 else f\"Record Node 111\"\n",
    "    vv = f\"Record Node 111\" if u == 0 else f\"Record Node 106\"\n",
    "    i = 1\n",
    "\n",
    "    try:\n",
    "        recording = session.recordnodes[w].recordings[x]\n",
    "        #recording_offline = session.recordnodes[w].recordings[x]\n",
    "    except IndexError:\n",
    "        print(f\"No recording {x+1} found in {exp}/{yy}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: x={x}, y={y}, exp={exp}, yy={yy}\")\n",
    "\n",
    "    # ==== Sync Setup ====\n",
    "    print(f\"\\n{exp.upper()}, Recording {x+1}\")\n",
    "    print(recording)\n",
    "\n",
    "    # Only add sync line if a main one doesn't already exist\n",
    "    has_main_sync = any(sync.get(\"main\", False) for sync in recording.sync_lines)\n",
    "    if not has_main_sync:\n",
    "        recording.add_sync_line(1, 100, 'Rhythm Data', main=True)\n",
    "\n",
    "    #recording.compute_global_timestamps()\n",
    "\n",
    "    metadata = recording.continuous[0].metadata\n",
    "    channel_names = metadata['channel_names']\n",
    "    print(\"Channels:\", channel_names, '\\n')\n",
    "\n",
    "    timestamps = recording.continuous[0].timestamps\n",
    "    #data_offline =  recording_offline.continuous[0].get_samples(start_sample_index=0, end_sample_index=len(timestamps))\n",
    "    data = recording.continuous[0].get_samples(start_sample_index=0, end_sample_index=len(timestamps))\n",
    "    sample_rate = metadata['sample_rate']\n",
    "\n",
    "    # ==== EMG Processing ====\n",
    "    # CHANNEL 11 or INDEX=3 of DATA is the ONLINE PROCESSED DATA STREAM OF DIFFERENTIAL EMG\n",
    "    differential_emg = data[:, 3]\n",
    "\n",
    "    # ==== Load ADC1 (for stim detection) ====\n",
    "    adc1 = np.abs(data[:, 4])  # adjust if your ADC1 channel index differs\n",
    "\n",
    "    # ==== Sync Events ====\n",
    "    events = recording.events\n",
    "    sync_events = events[(events.line == 1) & (events.processor_id == 100) &\n",
    "                            (events.stream_name == 'Rhythm Data') & (events.state == 1)]\n",
    "    sync_timestamps = sync_events['timestamp'].to_numpy()\n",
    "\n",
    "    # ==== Load MessageCenter ====\n",
    "    messagecenter_dir = os.path.join(directory, v, exp, yy, \"events\", \"MessageCenter\")\n",
    "    if not os.path.exists(messagecenter_dir):\n",
    "        print(f\"MessageCenter directory not found for {exp}/{yy}\")\n",
    "        continue\n",
    "\n",
    "    texts = np.load(os.path.join(messagecenter_dir, \"text.npy\"), allow_pickle=True)\n",
    "    timestamps_msg = np.load(os.path.join(messagecenter_dir, \"timestamps.npy\"))\n",
    "    decoded_texts = [t.decode('utf-8') if isinstance(t, bytes) else str(t) for t in texts]\n",
    "    message_entries = list(zip(timestamps_msg, decoded_texts))\n",
    "    print(f\"Loaded {len(decoded_texts)} MessageCenter entries\")\n",
    "\n",
    "    # ==== Debug Print ====\n",
    "    for text, time in zip(decoded_texts, timestamps_msg):\n",
    "        print(f\"[Time: {time:.6f} s] Message: {text}\")\n",
    "\n",
    "    # ==== Full Trace Plot ====\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(timestamps, differential_emg, label=\"Filtered EMG1 - EMG2\", color='purple')\n",
    "    plt.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "    plt.title(f\"{directory}, {exp}, {yy}, Absolute Value Filtered Differential EMG Signal (EMG1 - EMG2)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (μV)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.ylim(top=15000)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==== Peri-Stimulus Analysis with Shaded Stimulus Duration ====\n",
    "    pre_event_time = 5   # ms before calculated stim start\n",
    "    post_event_time = 20 # ms after calculated stim start\n",
    "    stim_threshold = 0.01 # ADC1 threshold to detect pulse (adjust if needed)\n",
    "    offstim_threshold = .41\n",
    "\n",
    "    peri_stim_segments = []\n",
    "    peri_stim_segments_adc1 = []\n",
    "    segment_stim_end_times = []\n",
    "    segment_stim_start_times = []\n",
    "\n",
    "    for stamp in sync_timestamps:\n",
    "        # First, find approximate sample index around the sync pulse\n",
    "        idx_center = np.searchsorted(timestamps, stamp)\n",
    "        # Define a generous window to locate true stim-onset in ADC1\n",
    "        idx_search_start = np.searchsorted(timestamps, stamp - 0.00003)  # 10 ms before sync\n",
    "        idx_search_end   = np.searchsorted(timestamps, stamp + 0.010)  # 10 ms after sync\n",
    "\n",
    "        if idx_search_start < 0 or idx_search_end > len(timestamps):\n",
    "            continue\n",
    "\n",
    "        adc1_segment_for_detection = adc1[idx_search_start:idx_search_end]\n",
    "        time_segment_for_detection = timestamps[idx_search_start:idx_search_end]\n",
    "\n",
    "        # Detect true stim start: first crossing above threshold in that window\n",
    "        above_idxs = np.where(adc1_segment_for_detection > stim_threshold)[0]\n",
    "        \n",
    "        if len(above_idxs) == 0:\n",
    "            continue\n",
    "        stim_start_idx = idx_search_start + above_idxs[0]\n",
    "        stim_start_time = timestamps[stim_start_idx]\n",
    "\n",
    "        # Now define peri-stimulus window around this stim_start_time\n",
    "        idx_pre  = int(stim_start_idx - (pre_event_time / 1000) * sample_rate)\n",
    "        idx_post = int(stim_start_idx + (post_event_time / 1000) * sample_rate)\n",
    "\n",
    "        if idx_pre < 0 or idx_post > len(timestamps):\n",
    "            continue\n",
    "\n",
    "        # Extract windows\n",
    "        time_window = timestamps[idx_pre:idx_post]\n",
    "        time_zeroed = time_window - stim_start_time  # in seconds\n",
    "\n",
    "        emg_window  = differential_emg[idx_pre:idx_post]\n",
    "        adc1_window = adc1[idx_pre:idx_post]\n",
    "\n",
    "        # Detect stim end: first time after stim_start where ADC1 falls back below threshold\n",
    "        post_onset_mask = (time_zeroed >= 0)\n",
    "        adc1_post_onset = adc1_window[post_onset_mask]\n",
    "        time_post_onset = time_zeroed[post_onset_mask]\n",
    "\n",
    "        below_idxs = np.where(adc1_post_onset < offstim_threshold)[0]\n",
    "        if len(below_idxs) > 0:\n",
    "            stim_end_time = time_post_onset[below_idxs[0]] * 1000  # convert to ms\n",
    "        else:\n",
    "            stim_end_time = post_event_time\n",
    "\n",
    "        # Save for grouping\n",
    "        peri_stim_segments.append((time_zeroed * 1000, emg_window, stim_end_time))\n",
    "        peri_stim_segments_adc1.append(adc1_window)\n",
    "        segment_stim_start_times.append(stim_start_time)\n",
    "        segment_stim_end_times.append(stim_end_time)\n",
    "\n",
    "\n",
    "    # ==== Dynamically determine stimulation groups based on event messages ====\n",
    "\n",
    "    # First, extract only trigger messages and stim setting messages\n",
    "    trigger_pattern = re.compile(r\"RHDCONTROL TRIGGER\")\n",
    "    stim_pattern = re.compile(r\"starting(?: at)? (\\d+\\.?\\d*)\\s*mA\", re.IGNORECASE)\n",
    "\n",
    "    stim_groups = []\n",
    "    current_group = []\n",
    "    current_amp = None\n",
    "    trigger_times = []\n",
    "\n",
    "    for t, msg in message_entries:\n",
    "        if stim_pattern.search(msg):\n",
    "            # Save the previous group if any\n",
    "            if current_amp is not None and current_group:\n",
    "                stim_groups.append((current_amp, current_group))\n",
    "            # Start new group\n",
    "            current_amp = float(stim_pattern.search(msg).group(1))\n",
    "            current_group = []\n",
    "        elif trigger_pattern.search(msg):\n",
    "            if current_amp is not None:\n",
    "                current_group.append(t)\n",
    "    \n",
    "    # Don't forget to save the last group\n",
    "    if current_amp is not None and current_group:\n",
    "        stim_groups.append((current_amp, current_group))\n",
    "\n",
    "    # ==== Match trigger times to peri_stim_segments ====\n",
    "    # Create dictionary to associate each stim amplitude to its segments\n",
    "    stim_intensities = []\n",
    "    m_wave_peaks = []\n",
    "    h_wave_peaks = []\n",
    "\n",
    "    \n",
    "    for stim_amp, trigger_times_group in stim_groups:\n",
    "    # For each trigger time, find matching peri_stim segment (by start time)\n",
    "        group_data = []\n",
    "        group_start_times = []\n",
    "        group_end_times = []\n",
    "        group_adc1 = []\n",
    "\n",
    "        for trig_time in trigger_times_group:\n",
    "            # Find closest stim_start_time to this trigger time\n",
    "            idx_match = np.argmin(np.abs(np.array(segment_stim_start_times) - trig_time))\n",
    "            # Extra check: ensure it's reasonably close (e.g., within 100 ms)\n",
    "            if abs(segment_stim_start_times[idx_match] - trig_time) < 0.1:\n",
    "                group_data.append(peri_stim_segments[idx_match])\n",
    "                group_adc1.append(peri_stim_segments_adc1[idx_match])\n",
    "                group_start_times.append(segment_stim_start_times[idx_match])\n",
    "                group_end_times.append(segment_stim_end_times[idx_match])\n",
    "\n",
    "        if not group_data:\n",
    "            continue  # skip if no valid matching data\n",
    "\n",
    "        # Proceed with same logic as original\n",
    "        time_ms_matrix = np.stack([gd[0] for gd in group_data])\n",
    "        emg_matrix     = np.stack([gd[1] for gd in group_data])\n",
    "\n",
    "        avg_time_ms = time_ms_matrix[0]  # identical for all in group\n",
    "        avg_adc1 = np.mean(group_adc1, axis=0)\n",
    "        avg_emg     = np.mean(emg_matrix, axis=0)\n",
    "        avg_end_ms  = np.mean(group_end_times)\n",
    "\n",
    "        stim_intensities.append(stim_amp)\n",
    "\n",
    "        plt.figure(figsize=(7, 5))\n",
    "\n",
    "        for (_, trace, _) in group_data:\n",
    "            plt.plot(avg_time_ms, trace, color='red', alpha=0.6)\n",
    "        plt.plot(avg_time_ms, avg_emg, color='black', linewidth=2, label='Average EMG')\n",
    "\n",
    "        plt.axvline(x=0, color='red', linestyle='--', label='_nolegend_')\n",
    "        plt.axvline(x=stim_end_time, color='red', linestyle='--', label='Stim Start/End')\n",
    "        plt.axvspan(0, stim_end_time, color='red', alpha=0.3)\n",
    "\n",
    "        \n",
    "\n",
    "        plt.axvspan(m_wave_start, m_wave_end, color='blue', alpha=0.3)\n",
    "        plt.axvspan(h_wave_start, h_wave_end, color='green', alpha=0.3)\n",
    "\n",
    "        m_wave_mask = (avg_time_ms >= m_wave_start) & (avg_time_ms <= m_wave_end)\n",
    "        m_wave_time_window = avg_time_ms[m_wave_mask]\n",
    "        m_wave_emg_window = avg_emg[m_wave_mask]\n",
    "        m_wave_peak_idx = np.argmax(m_wave_emg_window)\n",
    "        m_wave_peak_time = m_wave_time_window[m_wave_peak_idx]\n",
    "        m_wave_peak_amp = m_wave_emg_window[m_wave_peak_idx]\n",
    "        m_wave_peaks.append(m_wave_peak_amp)\n",
    "\n",
    "        h_wave_mask = (avg_time_ms >= h_wave_start) & (avg_time_ms <= h_wave_end)\n",
    "        h_wave_time_window = avg_time_ms[h_wave_mask]\n",
    "        h_wave_emg_window = avg_emg[h_wave_mask]\n",
    "        h_wave_peak_idx = np.argmax(h_wave_emg_window)\n",
    "        h_wave_peak_time = h_wave_time_window[h_wave_peak_idx]\n",
    "        h_wave_peak_amp = h_wave_emg_window[h_wave_peak_idx]\n",
    "        h_wave_peaks.append(h_wave_peak_amp)\n",
    "\n",
    "        plt.axvline(x=m_wave_peak_time, color='blue', linestyle=':', linewidth=2,\n",
    "                    label=f'M-Wave Peak: {m_wave_peak_amp:.1f} μV at {m_wave_peak_time:.2f} ms')\n",
    "        plt.axvline(x=h_wave_peak_time, color='green', linestyle=':', linewidth=2,\n",
    "                    label=f'H-Wave Peak: {h_wave_peak_amp:.1f} μV at {h_wave_peak_time:.2f} ms')\n",
    "\n",
    "        plt.text(m_wave_peak_time, m_wave_peak_amp + 200, f'{m_wave_peak_amp:.1f} μV',\n",
    "                color='blue', fontsize=9, ha='center')\n",
    "        plt.text(h_wave_peak_time, h_wave_peak_amp + 200, f'{h_wave_peak_amp:.1f} μV',\n",
    "                color='green', fontsize=9, ha='center')\n",
    "\n",
    "        plt.title(f\"{exp}, {yy}, Peri-Stimulus EMG \"\n",
    "                f\"(Events {i}-{i + (1)*len(group_data)}) | Stim Amp: {stim_amp} mA\")\n",
    "        plt.xlabel(\"Time (ms)\")\n",
    "        plt.ylabel(\"Amplitude (μV)\")\n",
    "        plt.grid(True)\n",
    "        plt.legend(\n",
    "            fontsize=7,\n",
    "            loc=\"upper left\",\n",
    "            frameon=True,\n",
    "            framealpha=0.8\n",
    "        )\n",
    "        plt.ylim(top=4500)\n",
    "\n",
    "        min_ms = int(np.floor(avg_time_ms[0]))\n",
    "        max_ms = int(np.ceil(avg_time_ms[-1]))\n",
    "        plt.xticks(np.arange(min_ms, max_ms + 1, 1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        i = i + (1)*len(group_data) + 1\n",
    "\n",
    "\n",
    "\n",
    "############################ THE CODE BELOW IS WITH THE ADC LINE PLOT ADDED ##################\n",
    "\n",
    "    '''\n",
    "\n",
    "    for stim_amp, trigger_times_group in stim_groups:\n",
    "        # For each trigger time, find matching peri_stim segment (by start time)\n",
    "        group_data = []\n",
    "        group_start_times = []\n",
    "        group_end_times = []\n",
    "        group_adc1 = []\n",
    "\n",
    "        for trig_time in trigger_times_group:\n",
    "            # Find closest stim_start_time to this trigger time\n",
    "            idx_match = np.argmin(np.abs(np.array(segment_stim_start_times) - trig_time))\n",
    "            # Extra check: ensure it's reasonably close (e.g., within 100 ms)\n",
    "            if abs(segment_stim_start_times[idx_match] - trig_time) < 0.1:\n",
    "                group_data.append(peri_stim_segments[idx_match])\n",
    "                group_adc1.append(peri_stim_segments_adc1[idx_match])\n",
    "                group_start_times.append(segment_stim_start_times[idx_match])\n",
    "                group_end_times.append(segment_stim_end_times[idx_match])\n",
    "\n",
    "        if not group_data:\n",
    "            continue  # skip if no valid matching data\n",
    "\n",
    "        # Proceed with same logic as original\n",
    "        time_ms_matrix = np.stack([gd[0] for gd in group_data])\n",
    "        emg_matrix     = np.stack([gd[1] for gd in group_data])\n",
    "\n",
    "        avg_time_ms = time_ms_matrix[0]  # identical for all in group\n",
    "        avg_adc1 = np.mean(group_adc1, axis=0)\n",
    "        avg_emg     = np.mean(emg_matrix, axis=0)\n",
    "        avg_end_ms  = np.mean(group_end_times)\n",
    "\n",
    "        stim_intensities.append(stim_amp)\n",
    "\n",
    "        #plt.figure(figsize=(7, 4))\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(7, 5), sharex=True, gridspec_kw={'height_ratios':[3,1]})\n",
    "\n",
    "        for (_, trace, _) in group_data:\n",
    "            axs[0].plot(avg_time_ms, trace, color='red', alpha=0.6)\n",
    "        axs[0].plot(avg_time_ms, avg_emg, color='black', linewidth=2, label='Average EMG')\n",
    "\n",
    "        axs[0].axvline(x=0, color='red', linestyle='--', label='Stim Start')\n",
    "\n",
    "        #plt.axvline(x=1.0, color='red', linestyle='--', label='_nolegend_')\n",
    "        #plt.axvspan(0, 1.0, color='red', alpha=0.3)\n",
    "\n",
    "        #---------------Here we can manually set the red box width for the stimm ----------------#\n",
    "        axs[0].axvline(x=stim_end_time, color='red', linestyle='--', label='Stim End')\n",
    "        axs[0].axvspan(0, stim_end_time, color='red', alpha=0.3)\n",
    "\n",
    "        m_wave_start, m_wave_end = 1.5,3\n",
    "        h_wave_start, h_wave_end = 4, 10\n",
    "\n",
    "        axs[0].axvspan(m_wave_start, m_wave_end, color='blue', alpha=0.3)\n",
    "        axs[0].axvspan(h_wave_start, h_wave_end, color='green', alpha=0.3)\n",
    "\n",
    "        m_wave_mask = (avg_time_ms >= m_wave_start) & (avg_time_ms <= m_wave_end)\n",
    "        m_wave_time_window = avg_time_ms[m_wave_mask]\n",
    "        m_wave_emg_window = avg_emg[m_wave_mask]\n",
    "        m_wave_peak_idx = np.argmax(m_wave_emg_window)\n",
    "        m_wave_peak_time = m_wave_time_window[m_wave_peak_idx]\n",
    "        m_wave_peak_amp = m_wave_emg_window[m_wave_peak_idx]\n",
    "        m_wave_peaks.append(m_wave_peak_amp)\n",
    "\n",
    "        h_wave_mask = (avg_time_ms >= h_wave_start) & (avg_time_ms <= h_wave_end)\n",
    "        h_wave_time_window = avg_time_ms[h_wave_mask]\n",
    "        h_wave_emg_window = avg_emg[h_wave_mask]\n",
    "        h_wave_peak_idx = np.argmax(h_wave_emg_window)\n",
    "        h_wave_peak_time = h_wave_time_window[h_wave_peak_idx]\n",
    "        h_wave_peak_amp = h_wave_emg_window[h_wave_peak_idx]\n",
    "        h_wave_peaks.append(h_wave_peak_amp)\n",
    "\n",
    "        axs[0].axvline(x=m_wave_peak_time, color='blue', linestyle=':', linewidth=2,\n",
    "                    label=f'M-Wave Peak: {m_wave_peak_amp:.1f} μV at {m_wave_peak_time:.2f} ms')\n",
    "        axs[0].axvline(x=h_wave_peak_time, color='green', linestyle=':', linewidth=2,\n",
    "                    label=f'H-Wave Peak: {h_wave_peak_amp:.1f} μV at {h_wave_peak_time:.2f} ms')\n",
    "\n",
    "        axs[0].text(m_wave_peak_time, m_wave_peak_amp + 200, f'{m_wave_peak_amp:.1f} μV',\n",
    "                 color='blue', fontsize=9, ha='center')\n",
    "        axs[0].text(h_wave_peak_time, h_wave_peak_amp + 200, f'{h_wave_peak_amp:.1f} μV',\n",
    "                 color='green', fontsize=9, ha='center')\n",
    "        \n",
    "        #plt.title(\n",
    "        #    f\"{exp}, {yy}, Peri-Stimulus EMG \"\n",
    "        #    f\"(Triggers: {len(group_data)}) | Stim Amp: {stim_amp} mA\"\n",
    "        #)\n",
    "        axs[0].set_title(\n",
    "            f\"{exp}, {yy}, Peri-Stimulus EMG \"\n",
    "            f\"(Events {i}-{i + (1)*len(group_data)}) | Stim Amp: {stim_amp} mA\"\n",
    "        )\n",
    "        axs[0].set_xlabel(\"Time (ms)\")\n",
    "        axs[0].set_ylabel(\"Amplitude (μV)\")\n",
    "        axs[0].grid(True)\n",
    "        axs[0].legend()\n",
    "        axs[0].set_ylim(top=1500)\n",
    "\n",
    "        min_ms = int(np.floor(avg_time_ms[0]))\n",
    "        max_ms = int(np.ceil(avg_time_ms[-1]))\n",
    "        axs[0].set_xticks(np.arange(min_ms, max_ms + 1, 1))\n",
    "        #axs[0].tick_params(labelbottom=True)\n",
    "        #axs[0].set_xlim(min_ms, max_ms)  # ensures full range is visible\n",
    "        #axs[0].set_xticks(np.arange(int(avg_time_ms[0])-1, int(avg_time_ms[-1])+2, 1))\n",
    "        #axs[0].set_xticks(np.arange(np.floor(avg_time_ms[0]), np.ceil(avg_time_ms[-1]) + 1, 1))\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        for (trace) in group_adc1:\n",
    "            axs[1].plot(avg_time_ms, trace, color='green', alpha=0.5)\n",
    "        axs[1].plot(avg_time_ms, avg_adc1, color='black', linewidth=2, label='Avg ADC1')\n",
    "        axs[1].axvline(0, color='red', linestyle='--', label='Stim Start')\n",
    "        axs[1].axvline(stim_end_time, color='red', linestyle='--', label='Stim End')\n",
    "        axs[1].set_title(\"Peri-Stimulus ADC1\")\n",
    "        axs[1].set_xlabel(\"Time (ms)\")\n",
    "        axs[1].set_ylabel(\"ADC1 Signal\")\n",
    "        axs[1].legend()\n",
    "        axs[1].grid(True)\n",
    "        axs[1].set_xticks(np.arange(min_ms, max_ms + 1, 1))\n",
    "        #axs[1].set_xlim(min_ms, max_ms)\n",
    "        #axs[1].set_xticks(np.arange(int(avg_time_ms[0])-1, int(avg_time_ms[-1])+2, 1))\n",
    "        #axs[1].set_xticks(np.arange(np.floor(avg_time_ms[0]), np.ceil(avg_time_ms[-1]) + 1, 1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        i = i + (1)*len(group_data) + 1\n",
    "    '''\n",
    "        \n",
    "\n",
    "    # ==== Group peak amplitudes by stimulation intensity ====\n",
    "    m_wave_dict = defaultdict(list)\n",
    "    h_wave_dict = defaultdict(list)\n",
    "\n",
    "    for amp, m_peak, h_peak in zip(stim_intensities, m_wave_peaks, h_wave_peaks):\n",
    "        m_wave_dict[amp].append(m_peak)\n",
    "        h_wave_dict[amp].append(h_peak)\n",
    "\n",
    "    # Sort by stimulation intensity\n",
    "    sorted_amps = sorted(set(stim_intensities))\n",
    "\n",
    "    m_wave_data = [m_wave_dict[amp] for amp in sorted_amps]\n",
    "    h_wave_data = [h_wave_dict[amp] for amp in sorted_amps]\n",
    "\n",
    "    # Compute mean and SEM for overlay\n",
    "    m_means = [np.mean(peaks) for peaks in m_wave_data]\n",
    "    m_sems  = [stats.sem(peaks) for peaks in m_wave_data]\n",
    "    h_means = [np.mean(peaks) for peaks in h_wave_data]\n",
    "    h_sems  = [stats.sem(peaks) for peaks in h_wave_data]\n",
    "\n",
    "    # ==== Plot Recruitment Curves as Box-and-Whisker ====\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    \n",
    "\n",
    "    # Boxplots\n",
    "    positions = np.arange(len(sorted_amps))  # for spacing\n",
    "    #box1 = ax.boxplot(m_wave_data, positions=positions - 0.2, widths=0.3,\n",
    "    #                patch_artist=True, boxprops=dict(facecolor='lightblue'),\n",
    "    #                medianprops=dict(color='black'), labels=[f\"{amp:.1f}\" for amp in sorted_amps])\n",
    "    #box2 = ax.boxplot(h_wave_data, positions=positions + 0.2, widths=0.3,\n",
    "    #                patch_artist=True, boxprops=dict(facecolor='lightgreen'),\n",
    "    #                medianprops=dict(color='black'))\n",
    "\n",
    "    #Overlay mean ± SEM\n",
    "    ax.errorbar(positions - 0.2, m_means, yerr=m_sems, fmt='o-', color='blue', label='M-Wave Mean ± SEM')\n",
    "    ax.errorbar(positions + 0.2, h_means, yerr=h_sems, fmt='o-', color='green', label='H-Wave Mean ± SEM')\n",
    "\n",
    "    # Aesthetics\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels([f\"{amp:.1f}\" for amp in sorted_amps])\n",
    "    ax.set_xlabel(\"Stimulation Intensity (mA)\")\n",
    "    ax.set_ylabel(\"Peak Amplitude (μV)\")\n",
    "    ax.set_title(f\"{exp}, {yy}, Recruitment Curves\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==== Group and Normalize Peak Amplitudes ====\n",
    "    m_wave_dict = defaultdict(list)\n",
    "    h_wave_dict = defaultdict(list)\n",
    "\n",
    "    # Ensure all amplitudes are absolute values\n",
    "    for amp, m_peak, h_peak in zip(stim_intensities, m_wave_peaks, h_wave_peaks):\n",
    "        m_wave_dict[amp].append(abs(m_peak))\n",
    "        h_wave_dict[amp].append(abs(h_peak))\n",
    "\n",
    "    # Sort stimulation intensities\n",
    "    sorted_amps = sorted(set(stim_intensities))\n",
    "    m_wave_data = [m_wave_dict[amp] for amp in sorted_amps]\n",
    "    h_wave_data = [h_wave_dict[amp] for amp in sorted_amps]\n",
    "\n",
    "    # Compute means\n",
    "    m_means = np.array([np.mean(peaks) for peaks in m_wave_data])\n",
    "    h_means = np.array([np.mean(peaks) for peaks in h_wave_data])\n",
    "    m_sems  = np.array([stats.sem(peaks) for peaks in m_wave_data])\n",
    "    h_sems  = np.array([stats.sem(peaks) for peaks in h_wave_data])\n",
    "\n",
    "    # Find M_max and normalize amplitudes\n",
    "    M_max = np.max(m_means)\n",
    "    m_means_norm = (m_means / M_max) * 100\n",
    "    h_means_norm = (h_means / M_max) * 100\n",
    "    m_sems_norm  = (m_sems  / M_max) * 100\n",
    "    h_sems_norm  = (h_sems  / M_max) * 100\n",
    "\n",
    "    # Interpolate M-curve to find current at 50% M_max\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    interp_func = interp1d(m_means_norm, sorted_amps, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "    try:\n",
    "        current_at_50_percent = float(interp_func(50))\n",
    "    except:\n",
    "        current_at_50_percent = sorted_amps[np.argmax(m_means_norm >= 50)]\n",
    "\n",
    "    # Normalize current axis\n",
    "    normalized_currents = np.array(sorted_amps) / current_at_50_percent\n",
    "\n",
    "    # Mark H_max (point \"a\") and Current at H_max (point \"b\")\n",
    "    H_max = np.max(h_means_norm)\n",
    "    idx_Hmax = np.argmax(h_means_norm)\n",
    "    current_at_Hmax_norm = normalized_currents[idx_Hmax]\n",
    "\n",
    "    # ==== Plot Normalized Recruitment Curves ====\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Overlay normalized mean ± SEM\n",
    "    ax.errorbar(normalized_currents - 0.02, m_means_norm, yerr=m_sems_norm, fmt='o-', color='blue', label='M-Wave (% Mmax)')\n",
    "    ax.errorbar(normalized_currents + 0.02, h_means_norm, yerr=h_sems_norm, fmt='o-', color='green', label='H-Wave (% Mmax)')\n",
    "\n",
    "    # Add point \"a\" (H_max) and \"b\" (Current at H_max)\n",
    "    ax.axhline(H_max, color='green', linestyle='--', linewidth=1, label=f'H_max = {H_max:.1f}% Mmax')\n",
    "    ax.axvline(current_at_Hmax_norm, color='gray', linestyle='--', linewidth=1, label=f'Current at H_max = {current_at_Hmax_norm:.2f}x')\n",
    "\n",
    "    # Add labels\n",
    "    ax.text(current_at_Hmax_norm + 0.02, H_max + 2, 'b', fontsize=12, color='black')\n",
    "    ax.text(normalized_currents[idx_Hmax] - 0.08, H_max + 2, 'a', fontsize=12, color='black')\n",
    "\n",
    "    # Aesthetics\n",
    "    #ax.set_xticks(np.round(normalized_currents, 2))\n",
    "    #ax.set_xticklabels([f\"{x:.2f}\" for x in normalized_currents])\n",
    "    ax.set_xlabel(\"Current (Normalized to Current at 50% Mmax)\")\n",
    "    ax.set_ylabel(\"H and M Wave Amplitude (% of Mmax)\")\n",
    "    ax.set_title(f\"{exp}, {yy}, Normalized Recruitment Curves\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    # Set window size here\n",
    "    #ax.set_xlim(right=2)\n",
    "    #ax.set_xlim(left=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e871bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_end_ms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mavg_end_ms\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(stim_end_time)\n",
      "\u001b[31mNameError\u001b[39m: name 'avg_end_ms' is not defined"
     ]
    }
   ],
   "source": [
    "print(avg_end_ms)\n",
    "print(stim_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b4cc1ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adc1_post_onset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43madc1_post_onset\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'adc1_post_onset' is not defined"
     ]
    }
   ],
   "source": [
    "print(adc1_post_onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cb842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc231a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c05bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.760000000580476)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_end_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab50bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m h_sems  = np.array([stats.sem(peaks) \u001b[38;5;28;01mfor\u001b[39;00m peaks \u001b[38;5;129;01min\u001b[39;00m h_wave_data])\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Find M_max and normalize amplitudes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m M_max = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm_means\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m m_means_norm = (m_means / M_max) * \u001b[32m100\u001b[39m\n\u001b[32m     24\u001b[39m h_means_norm = (h_means / M_max) * \u001b[32m100\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dal866445\\Documents\\Github\\open-ephys-python-tools\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3164\u001b[39m, in \u001b[36mmax\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   3052\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[32m   3053\u001b[39m \u001b[38;5;129m@set_module\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3054\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmax\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, initial=np._NoValue,\n\u001b[32m   3055\u001b[39m          where=np._NoValue):\n\u001b[32m   3056\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3057\u001b[39m \u001b[33;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[32m   3058\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3162\u001b[39m \u001b[33;03m    5\u001b[39;00m\n\u001b[32m   3163\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3165\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dal866445\\Documents\\Github\\open-ephys-python-tools\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# ==== Group and Normalize Peak Amplitudes ====\n",
    "m_wave_dict = defaultdict(list)\n",
    "h_wave_dict = defaultdict(list)\n",
    "\n",
    "# Ensure all amplitudes are absolute values\n",
    "for amp, m_peak, h_peak in zip(stim_intensities, m_wave_peaks, h_wave_peaks):\n",
    "    m_wave_dict[amp].append(abs(m_peak))\n",
    "    h_wave_dict[amp].append(abs(h_peak))\n",
    "\n",
    "# Sort stimulation intensities\n",
    "sorted_amps = sorted(set(stim_intensities))\n",
    "m_wave_data = [m_wave_dict[amp] for amp in sorted_amps]\n",
    "h_wave_data = [h_wave_dict[amp] for amp in sorted_amps]\n",
    "\n",
    "# Compute means\n",
    "m_means = np.array([np.mean(peaks) for peaks in m_wave_data])\n",
    "h_means = np.array([np.mean(peaks) for peaks in h_wave_data])\n",
    "m_sems  = np.array([stats.sem(peaks) for peaks in m_wave_data])\n",
    "h_sems  = np.array([stats.sem(peaks) for peaks in h_wave_data])\n",
    "\n",
    "# Find M_max and normalize amplitudes\n",
    "M_max = np.max(m_means)\n",
    "m_means_norm = (m_means / M_max) * 100\n",
    "h_means_norm = (h_means / M_max) * 100\n",
    "m_sems_norm  = (m_sems  / M_max) * 100\n",
    "h_sems_norm  = (h_sems  / M_max) * 100\n",
    "\n",
    "# Interpolate M-curve to find current at 50% M_max\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "interp_func = interp1d(m_means_norm, sorted_amps, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "try:\n",
    "    current_at_50_percent = float(interp_func(50))\n",
    "except:\n",
    "    current_at_50_percent = sorted_amps[np.argmax(m_means_norm >= 50)]\n",
    "\n",
    "# Normalize current axis\n",
    "normalized_currents = np.array(sorted_amps) / current_at_50_percent\n",
    "\n",
    "# Mark H_max (point \"a\") and Current at H_max (point \"b\")\n",
    "H_max = np.max(h_means_norm)\n",
    "idx_Hmax = np.argmax(h_means_norm)\n",
    "current_at_Hmax_norm = normalized_currents[idx_Hmax]\n",
    "\n",
    "# ==== Plot Normalized Recruitment Curves ====\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "# Overlay normalized mean ± SEM\n",
    "ax.errorbar(normalized_currents - 0.02, m_means_norm, yerr=m_sems_norm, fmt='o-', color='blue', label='M-Wave (% Mmax)')\n",
    "ax.errorbar(normalized_currents + 0.02, h_means_norm, yerr=h_sems_norm, fmt='o-', color='green', label='H-Wave (% Mmax)')\n",
    "\n",
    "# Add point \"a\" (H_max) and \"b\" (Current at H_max)\n",
    "ax.axhline(H_max, color='green', linestyle='--', linewidth=1, label=f'H_max = {H_max:.1f}% Mmax')\n",
    "ax.axvline(current_at_Hmax_norm, color='gray', linestyle='--', linewidth=1, label=f'Current at H_max = {current_at_Hmax_norm:.2f}x')\n",
    "\n",
    "# Add labels\n",
    "ax.text(current_at_Hmax_norm + 0.02, H_max + 2, 'b', fontsize=12, color='black')\n",
    "ax.text(normalized_currents[idx_Hmax] - 0.08, H_max + 2, 'a', fontsize=12, color='black')\n",
    "\n",
    "# Aesthetics\n",
    "ax.set_xticks(np.round(normalized_currents, ))\n",
    "ax.set_xticklabels([f\"{x:.1f}\" for x in normalized_currents])\n",
    "ax.set_xlabel(\"Current (Normalized to Current at 50% Mmax)\", fontsize=16)\n",
    "ax.set_ylabel(\"H and M Wave Amplitude (% of Mmax)\", fontsize=16)\n",
    "ax.set_title(f\"{exp}, {yy}, Normalized Recruitment Curves\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_xlim(right=1.4)\n",
    "ax.set_xlim(left=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ==== Plot Recruitment Curves as Box-and-Whisker ====\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "\n",
    "\n",
    "# Boxplots\n",
    "positions = np.arange(len(sorted_amps))  # for spacing\n",
    "\n",
    "#Overlay mean ± SEM\n",
    "ax.errorbar(positions - 0.2, m_means, yerr=m_sems, fmt='o-', color='blue', label='M-Wave Mean ± SEM')\n",
    "ax.errorbar(positions + 0.2, h_means, yerr=h_sems, fmt='o-', color='green', label='H-Wave Mean ± SEM')\n",
    "\n",
    "# Aesthetics\n",
    "ax.set_xticks(positions)\n",
    "tick_labels = []\n",
    "for i, amp in enumerate(sorted_amps):\n",
    "    if i % 10 == 0:  # show every 10th label\n",
    "        tick_labels.append(f\"{amp:.1f}\")\n",
    "    else:\n",
    "        tick_labels.append(\"\")  # leave blank\n",
    "\n",
    "ax.set_xticklabels(tick_labels)\n",
    "\n",
    "#ax.set_xticklabels([f\"{amp:.1f}\" for amp in sorted_amps])\n",
    "ax.set_xlabel(\"Stimulation Intensity (mA)\")\n",
    "ax.set_ylabel(\"Peak Amplitude (μV)\")\n",
    "ax.set_title(f\"{exp}, {yy}, Recruitment Curves\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b79b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
